import logging
import uuid
from typing import Dict
from django.conf import settings
import google.generativeai as genai
from google.cloud import firestore
from google.oauth2 import service_account
import os
import json

logger = logging.getLogger(__name__)

cred_path = os.environ.get("FIRESTORE_CREDENTIALS", "./gen-lang-client-0000121060-ea7b2bef1534.json")
credentials = service_account.Credentials.from_service_account_file(cred_path)
DATABASE = firestore.Client(credentials=credentials)

class GeminiService:
    def __init__(self):
        try:
            if settings.GEMINI_API_KEY:
                genai.configure(api_key=settings.GEMINI_API_KEY)
                # ìµœì‹  Gemini ëª¨ë¸ ì‚¬ìš© (gemini-pro ëŒ€ì‹  gemini-1.5-flash ë˜ëŠ” gemini-1.5-pro)
                self.model = genai.GenerativeModel('gemini-2.5-flash')
                logger.info("Gemini AI initialized successfully with gemini-1.5-flash")
            else:
                logger.error("GEMINI_API_KEY not found in settings")
                self.model = None
        except Exception as e:
            logger.error(f"Failed to initialize Gemini AI: {e}")
            self.model = None
            
    def process_query(self, user_query):
        try:
            db = DATABASE
            collections = db.collection('tour_list').get()
            all_spots = [
                {
                    'id': collection.to_dict().get('id', ''),
                    'name': collection.to_dict().get('name', ''),
                    'overview': collection.to_dict().get('overview', ''),
                    'category': collection.to_dict().get('category', ''),
                } for collection in collections
            ]
            
            recommendation_result = self.recommend_tourism_spots(user_query, all_spots)

            full_spots = []
            for spot in recommendation_result.get('recommended_spots', []):
                try:
                    item = db.collection('tour_list').document(spot['id']).get().to_dict()
                    full_spots.append({
                        'addr1': item.get('addr1', ''),
                        'addr2': item.get('addr2', ''),
                        'areacode': item.get('areacode', ''),
                        'cat1': item.get('cat1', ''),
                        'cat2': item.get('cat2', ''),
                        'cat3': item.get('cat3', ''),
                        'contentid': item.get('contentid', ''),
                        'contenttypeid': item.get('contenttypeid', ''),
                        'createdtime': item.get('createdtime', ''),
                        'firstimage': item.get('firstimage', ''),
                        'firstimage2': item.get('firstimage2', ''),
                        'mapx': item.get('mapx', ''),
                        'mapy': item.get('mapy', ''),
                        'tel': item.get('tel', ''),
                        'title': item.get('title', ''),
                        'zipcode': item.get('zipcode', ''),
                        'overview': item.get('overview', ''),
                        'price': item.get('price', ''),
                    })
                except Exception as e:
                    logger.error(f"Error fetching full spot details for {spot['id']}: {e}")
                    continue
                
            recommendation_result['recommended_spots'] = full_spots
            
            response_data = {
                    'success': True,
                    'query': user_query,
                    'analysis': recommendation_result.get('analysis', {}),
                    'recommended_spots': recommendation_result.get('recommended_spots', []),
            }
            return response_data
        except Exception as e:
            logger.error(f"Error processing query: {e}")
            return {'success': False, 'message': str(e)}

    def recommend_tourism_spots(self, user_query: str, all_spots: list, max_results: int = 30) -> Dict:
        """ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê´€ê´‘ì§€ ì¶”ì²œ"""
        try:
            # 1. ì¿¼ë¦¬ ë¶„ì„
            analysis_result = self.analyze_user_query(user_query)
            
            if not analysis_result['success']:
                return analysis_result
            
            analysis = analysis_result['analysis']
            
            # 2. ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ê´€ê´‘ì§€ ì¶”ì²œ
            recommended_spots = []
            keywords = analysis.get('keywords', [])
            
            for spot in all_spots:
                # í‚¤ì›Œë“œê°€ ì´ë¦„ì´ë‚˜ ê°œìš”ì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                spot_text = f"{spot.get('name', '')} {spot.get('overview', '')}".lower()
                for keyword in keywords:
                    if keyword.lower() in spot_text:
                        recommended_spots.append(spot)
                        break
            
            # í‚¤ì›Œë“œ ë§¤ì¹­ì´ ì—†ìœ¼ë©´ ì „ì²´ ëª©ë¡ì—ì„œ ì¼ë¶€ë§Œ ë°˜í™˜
            if not recommended_spots:
                recommended_spots = all_spots[:max_results]
            
            # ê²°ê³¼ ìˆ˜ ì œí•œ
            recommended_spots = recommended_spots[:max_results]
            
            return {
                'success': True,
                'query': user_query,
                'analysis': analysis,
                'recommended_spots': recommended_spots,
                'total_found': len(recommended_spots),
                'returned_count': len(recommended_spots)
            }
            
        except Exception as e:
            logger.error(f"Error recommending tourism spots: {e}")
            return {'success': False, 'message': str(e)}
    
    def analyze_user_query(self, user_query: str) -> Dict:
        """ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ì—¬ ê´€ê´‘ì§€ ê²€ìƒ‰ ì¡°ê±´ ì¶”ì¶œ"""
        try:
            # Gemini AI ìƒíƒœ ìƒì„¸ ë¡œê¹…
            logger.info(f"=== Gemini AI ìƒíƒœ í™•ì¸ ===")
            logger.info(f"self.model ì¡´ì¬: {self.model is not None}")
            logger.info(f"GEMINI_API_KEY ì„¤ì •: {bool(getattr(settings, 'GEMINI_API_KEY', None))}")
            
            # if not self.model:
            #     logger.warning("âš ï¸ Gemini AI not available, using fallback analysis")
            #     logger.warning("Gemini AIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ í´ë°± ë¶„ì„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤")
            #     return self._fallback_analysis(user_query)
            
            logger.info("âœ… Gemini AI ì‚¬ìš© ê°€ëŠ¥ - ì‹¤ì œ AI ë¶„ì„ ì‹œì‘")
            
            # ì˜ì„±êµ° ê´€ê´‘ì§€ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._create_analysis_prompt(user_query)
            logger.info(f"Generated prompt length: {len(prompt)}")
            
            logger.info("ğŸ¤– Gemini AI í˜¸ì¶œ ì¤‘...")
            response = self.model.generate_content(prompt)
            logger.info(f"âœ… Gemini AI ì‘ë‹µ ë°›ìŒ: {response.text[:100]}...")
            
            # ì‘ë‹µ íŒŒì‹±
            analysis_result = self._parse_analysis_response(response.text)
            
            logger.info(f"Query analysis completed for: {user_query}")
            logger.info(f"Analysis result: {analysis_result}")
            
            return {
                'success': True,
                'original_query': user_query,
                'analysis': analysis_result,
                'processed_query': analysis_result.get('processed_query', user_query),
                'gemini_used': True  # Geminiê°€ ì‹¤ì œë¡œ ì‚¬ìš©ë˜ì—ˆìŒì„ í‘œì‹œ
            }
            
        except Exception as e:
            logger.error(f"âŒ Error analyzing user query with Gemini: {e}")
            import traceback
            logger.error(f"Gemini ì˜¤ë¥˜ ìƒì„¸: {traceback.format_exc()}")
            return {
                'success': False,
                'message': str(e),
                'original_query': user_query,
                'analysis': {
                    'keywords': [],
                    'categories': [],
                    'preferences': [],
                    'intent': 'general_search',
                    'processed_query': user_query,
                    'confidence': 0.5
                },
                'gemini_used': False  # Geminiê°€ ì‚¬ìš©ë˜ì§€ ì•Šì•˜ìŒì„ í‘œì‹œ
            }
        
        
    def _create_analysis_prompt(self, user_query: str) -> str:

        """ì‚¬ìš©ì ì¿¼ë¦¬ ë¶„ì„ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return f"""
        ì˜ì„±êµ° ê´€ê´‘ì§€ ì¶”ì²œ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìì—°ì–´ ì¿¼ë¦¬ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.

        ì‚¬ìš©ì ì¿¼ë¦¬: "{user_query}"

        ë‹¤ìŒ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ JSON í˜•íƒœë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”:
        {{
            "keywords": ["ì¶”ì¶œëœ í‚¤ì›Œë“œë“¤"],
            "categories": ["ê´€ê´‘ì§€ ì¹´í…Œê³ ë¦¬ë“¤"],
            "preferences": ["ì‚¬ìš©ì ì„ í˜¸ì‚¬í•­ë“¤"],
            "intent": "ì‚¬ìš©ì ì˜ë„",
            "processed_query": "ì •ì œëœ ê²€ìƒ‰ ì¿¼ë¦¬",
            "confidence": 0.0-1.0
        }}

        ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬:
        - ë¬¸í™”ì¬/ìœ ì ì§€
        - ìì—°ê´€ê´‘ì§€
        - ì²´í—˜ê´€ê´‘ì§€
        - ì¶•ì œ/ì´ë²¤íŠ¸
        - ìŒì‹/ë§›ì§‘
        - ìˆ™ë°•ì‹œì„¤
        - ë ˆì €/ìŠ¤í¬ì¸ 

        ì˜ì„±êµ°ì˜ íŠ¹ìƒ‰:
        - ë§ˆëŠ˜ê³¼ ì–‘íŒŒì˜ ê³ ì¥
        - ì¡°ë¬¸êµ­ ìœ ì ì§€
        - ë¹™ê³„ê³„ê³¡
        - ì‚¬ì´Œì—­ ì€í–‰ë‚˜ë¬´
        - ì˜ì„± ì¡°ë¬¸êµ­ì‚¬ì ì§€
        """
    
    def _parse_analysis_response(self, response_text: str) -> Dict:
        """AI ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜"""
        try:
            # JSON ë¶€ë¶„ ì¶”ì¶œ
            start_idx = response_text.find('{')
            end_idx = response_text.rfind('}') + 1
            
            if start_idx != -1 and end_idx != -1:
                json_str = response_text[start_idx:end_idx]
                return json.loads(json_str)
            else:
                # JSON í˜•íƒœê°€ ì•„ë‹Œ ê²½ìš° ê¸°ë³¸ê°’ ë°˜í™˜
                return {
                    'keywords': [response_text.strip()],
                    'categories': [],
                    'preferences': [],
                    'intent': 'general_search',
                    'processed_query': response_text.strip(),
                    'confidence': 0.5
                }
                
        except json.JSONDecodeError:
            logger.warning(f"Failed to parse AI response as JSON: {response_text}")
            return {
                'keywords': [],
                'categories': [],
                'preferences': [],
                'intent': 'unknown',
                'processed_query': response_text.strip(),
                'confidence': 0.3
            }



        